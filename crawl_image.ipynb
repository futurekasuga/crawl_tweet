{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d3f508d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT\n",
    "import os\n",
    "import tweepy\n",
    "import time \n",
    "import urllib.request, urllib.error\n",
    "import pandas as pd\n",
    "\n",
    "# 画像の保存先\n",
    "#保存先のパス名を「＊＊＊＊＊」に入力\n",
    "IMG_DIR = './YYYYY/'\n",
    "\n",
    "# 環境変数\n",
    "CONSUMER_KEY        = \"XXXXX\"\n",
    "CONSUMER_SECRET     = \"XXXXX\"\n",
    "ACCESS_TOKEN_KEY    = \"XXXXX\"\n",
    "ACCESS_TOKEN_SECRET = \"XXXXX\"\n",
    "\n",
    "# 検索キーワード\n",
    "#好きなキーワードを「＊＊＊＊＊」に入力\n",
    "TARGET = '#リコリコ min_faves:400 min_retweets:200'\n",
    "\n",
    "labels=[\n",
    "        'ツイートID',\n",
    "        'ツイート時刻',\n",
    "        'ツイート本文',\n",
    "        'いいね数',\n",
    "        'リツイート数',\n",
    "        'ユーザーID',\n",
    "        'ユーザー名',\n",
    "        'アカウント名',\n",
    "        '自己紹介文',\n",
    "        'フォロー数',\n",
    "        'フォロワー数',\n",
    "        'アカウント作成日時',\n",
    "        '自分のフォロー状況',\n",
    "        'アイコン画像URL',\n",
    "        'ヘッダー画像URL',\n",
    "        'WEBサイト',\n",
    "        '画像URL1',\n",
    "        '画像URL2',\n",
    "        '画像URL3',\n",
    "        '画像URL4',\n",
    "        ]\n",
    "\n",
    "# 検索オプション\n",
    "SEARCH_PAGES_NUMBER = 10000 # 読み込むページ数\n",
    "PER_PAGE_NUMBER = 100 # ページごとに返されるツイートの数（最大100）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "817a8d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class imageDownloader(object):\n",
    "    def __init__(self):\n",
    "        \"\"\"初期設定\n",
    "        \"\"\"\n",
    "        super(imageDownloader, self).__init__()\n",
    "        self.set_api()\n",
    "\n",
    "    def run(self):\n",
    "        \"\"\"実行\n",
    "            1. twitterページを指定数取得\n",
    "            2. ページ内のツイートのうち、キーワードがあるtweetのみ取得\n",
    "            3. 画像URLを取得\n",
    "            4. ダウンロード実行\n",
    "        \"\"\"\n",
    "        self.max_id = None # ページを跨ぐ検索対象IDの初期化\n",
    "        for page in range(SEARCH_PAGES_NUMBER):\n",
    "            ret_url_list = self.search(TARGET, PER_PAGE_NUMBER)\n",
    "            for url in ret_url_list:\n",
    "                print('OK ' + url)\n",
    "                self.download(url)\n",
    "            time.sleep(0.5) # TimeOut防止\n",
    "\n",
    "    def set_api(self):\n",
    "        \"\"\"apiの設定\n",
    "        \"\"\"\n",
    "        auth = tweepy.OAuthHandler(CONSUMER_KEY, CONSUMER_SECRET)\n",
    "        auth.set_access_token(ACCESS_TOKEN_KEY, ACCESS_TOKEN_SECRET)\n",
    "        self.api = tweepy.API(auth)\n",
    "\n",
    "    def search(self, target, rpp):\n",
    "        \"\"\"twitterで検索実行\n",
    "        \"\"\"\n",
    "        # 検索結果\n",
    "        ret_url_list = []\n",
    "\n",
    "        try:\n",
    "            # 検索実行\n",
    "            if self.max_id:\n",
    "                # q: クエリ文字列, rpp: ツイート数, max_id: より小さい（古い）IDを持つステータスのみを返す\n",
    "                res_search = self.api.search_tweets(q=target, lang='ja', count=rpp, max_id=self.max_id, tweet_mode = 'extended')\n",
    "            else:\n",
    "                res_search = self.api.search_tweets(q=target, lang='ja', count=rpp, tweet_mode = 'extended')\n",
    "            # 結果を保存\n",
    "            save_tweet_data(res_search)\n",
    "            for result in res_search:\n",
    "                if 'media' not in result.entities: continue\n",
    "                for media in result.extended_entities['media']:\n",
    "                    url = media['media_url_https']\n",
    "                    if url not in ret_url_list: ret_url_list.append(url)\n",
    "            # 検索済みidの更新し、より古いツイートを検索させる\n",
    "            self.max_id = result.id\n",
    "            # 検索結果の返却\n",
    "            return ret_url_list\n",
    "        except Exception as e:\n",
    "            self.error_catch(e)\n",
    "\n",
    "    def download(self, url):\n",
    "        \"\"\"画像のダウンロード\n",
    "        \"\"\"\n",
    "        url_orig = '%s?format=jpg&name=4096x4096' % url\n",
    "        path = IMG_DIR + url.split('/')[-1]\n",
    "        try:\n",
    "            response = urllib.request.urlopen(url=url_orig)\n",
    "            with open(path, \"wb\") as f:\n",
    "                f.write(response.read())\n",
    "        except Exception as e:\n",
    "            self.error_catch(e)\n",
    "\n",
    "    def error_catch(self, error):\n",
    "        \"\"\"エラー処理\n",
    "        \"\"\"\n",
    "        print(\"NG \", error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8c6c17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_tweet_data(res_search):\n",
    "    tw_data = []\n",
    "    \n",
    "    for result in res_search:\n",
    "        if 'media' not in result.entities: continue\n",
    "        tw_data.append([\n",
    "                result.id,\n",
    "                result.created_at.strftime('%Y-%m-%d %H:%M:%S'),\n",
    "                result.full_text,\n",
    "                result.favorite_count, \n",
    "                result.retweet_count, \n",
    "                result.user.id, \n",
    "                result.user.screen_name,\n",
    "                result.user.name,\n",
    "                result.user.description,\n",
    "                result.user.friends_count,\n",
    "                result.user.followers_count,\n",
    "                result.user.created_at.strftime('%Y-%m-%d %H:%M:%S'),\n",
    "                result.user.following,\n",
    "                result.user.profile_image_url,\n",
    "                result.user.profile_background_image_url,\n",
    "                result.user.url\n",
    "                               ])\n",
    "        media_urls = [media['media_url_https'] for media in result.extended_entities[\"media\"]]\n",
    "        tw_data[-1] += media_urls\n",
    "        while len(tw_data[-1]) < 20:\n",
    "            tw_data[-1].append(None)\n",
    "    \n",
    "    df = pd.DataFrame(tw_data,columns=labels)\n",
    "    df.to_csv(\"./tweet.csv\", mode='a', header=False, index=False)"
   ]
  },
  
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "bf7a5c41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
